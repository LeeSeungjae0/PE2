{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1acb8cc-5e20-4d07-81f7-d68749e2f784",
      "metadata": {
        "id": "f1acb8cc-5e20-4d07-81f7-d68749e2f784"
      },
      "source": [
        "# **Program Functions** <a id=\"program-functions\"></a>\n",
        "\n",
        "This section outlines the main functions and features of the program. It provides a detailed description of what the program does and how it performs its tasks. Key features may include:\n",
        "\n",
        "- Core functionality\n",
        "- Additional features\n",
        "- Any special capabilities or tools integrated into the program"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need tp install\n",
        "%pip install lmfit"
      ],
      "metadata": {
        "id": "B1IklKjUNCvC"
      },
      "id": "B1IklKjUNCvC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required packages\n",
        "import os\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from scipy.signal import find_peaks\n",
        "import numpy as np\n",
        "from decimal import Decimal\n",
        "from lmfit import Parameters, Minimizer, Model\n",
        "import xml.etree.ElementTree as eT"
      ],
      "metadata": {
        "id": "QK6axLGKZEQ8"
      },
      "id": "QK6axLGKZEQ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **os**: This module provides functions to interact with the operating system. It allows manipulation of file paths, accessing environment variables, etc.\n",
        "\n",
        "2. **datetime**: This module provides classes for manipulating dates and times. It supports conversion, comparison, and operations with date and time formats.\n",
        "\n",
        "3. **sys**: This module provides functions and variables to interact with the Python interpreter. It allows access to command-line arguments and modification of interpreter settings.\n",
        "\n",
        "4. **pandas (pd)**: This library is used for data manipulation and analysis. It facilitates handling tabular data structures, offering features like reading, writing, filtering, aggregating, and merging data.\n",
        "\n",
        "5. **matplotlib.pyplot (plt)**: This library is used for data visualization. It provides functions to create various types of charts such as line plots, bar charts, scatter plots, etc., and allows customization of styles and labels.\n",
        "\n",
        "6. **matplotlib.ticker.FuncFormatter**: This class in matplotlib allows formatting axis labels using custom functions. It enables users to format axis labels based on specific requirements.\n",
        "\n",
        "7. **scipy.signal.find_peaks**: This function from the scipy library is used in signal processing to find peaks in a given array. It is useful for analyzing patterns or specific structures in signals.\n",
        "\n",
        "8. **numpy (np)**: This library is essential for scientific computing. It provides support for multidimensional arrays and matrix operations, offering powerful numerical computing and data manipulation capabilities.\n",
        "\n",
        "9. **decimal.Decimal**: This class provides support for decimal floating point arithmetic. It is used when precise and predictable arithmetic is required, especially in financial and other exact computations.\n",
        "\n",
        "10. **lmfit.Parameters, lmfit.Minimizer, lmfit.Model**: These classes from the lmfit library are used for parameter optimization. They allow fitting models to data and estimating optimized parameters based on the given data.\n",
        "\n",
        "11. **xml.etree.ElementTree (eT)**: This built-in library is used for parsing and manipulating XML documents. It manages XML elements in a tree structure, allowing traversal and manipulation of XML data.\n"
      ],
      "metadata": {
        "id": "_e5kOIvTIdWl"
      },
      "id": "_e5kOIvTIdWl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGzWn4Ol2hJX"
      },
      "source": [
        "## **setting.py**"
      ],
      "id": "xGzWn4Ol2hJX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLAZqaWA2hJd"
      },
      "outputs": [],
      "source": [
        "def set_up(directory0, directory1, directory2, current_directory, testsite, xlsx_file, graph_image):\n",
        "    base_directory = os.path.join(current_directory, 'dat', directory0)\n",
        "    data_dict = create_data_frame()\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    print (timestamp)\n",
        "    if directory1.lower() == 'all':\n",
        "        if not os.path.isdir(base_directory):\n",
        "            print(f\"The base directory {base_directory} does not exist.\")\n",
        "        else:\n",
        "            for dir1 in os.listdir(base_directory):\n",
        "                dir1_path = os.path.join(base_directory, dir1)\n",
        "                if not os.path.isdir(dir1_path):\n",
        "                    print(f\"The directory {dir1_path} does not exist or is not a directory.\")\n",
        "                    continue\n",
        "                for dir12 in os.listdir(dir1_path):\n",
        "                    xml_directory = os.path.join(dir1_path, dir12)\n",
        "                    if os.path.isdir(xml_directory):\n",
        "                        main(directory0, dir1, dir12, current_directory, data_dict, testsite, graph_image, timestamp)\n",
        "    else:\n",
        "        if directory2.lower() == 'all':\n",
        "            base_directory2 = os.path.join(current_directory, 'dat', directory0, directory1)\n",
        "            if not os.path.isdir(base_directory2):\n",
        "                print(f\"The base directory {base_directory2} does not exist.\")\n",
        "            else:\n",
        "                for dir2 in os.listdir(base_directory2):\n",
        "                    xml_directory = os.path.join(base_directory2, dir2)\n",
        "                    if os.path.isdir(xml_directory):\n",
        "                        main(directory0, directory1, dir2, current_directory, data_dict, testsite, graph_image, timestamp)\n",
        "        else:\n",
        "            main(directory0, directory1, directory2, current_directory, data_dict, testsite, graph_image, timestamp)\n",
        "\n",
        "    if xlsx_file:\n",
        "        output_directory = os.path.join(current_directory, 'res',timestamp, 'xlsx')\n",
        "        os.makedirs(output_directory, exist_ok=True)\n",
        "        xlsx_file_path = os.path.join(output_directory, f'analysis_result.xlsx')\n",
        "        save_data_frame(data_dict, xlsx_file_path)\n",
        "    print('Data analysis is complete.')\n"
      ],
      "id": "HLAZqaWA2hJd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: **set_up**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Sets up and executes data processing and plotting for multiple directories of XML files based on provided parameters.\n",
        "- **Parameters**:\n",
        "  - `directory0`, `directory1`, `directory2`: Subdirectories within `current_directory` where XML files are located. They may be specified as 'all' to iterate over all subdirectories.\n",
        "  - `current_directory`: Root directory containing subdirectories where XML files reside.\n",
        "  - `testsite`: List of test site names used to filter XML files.\n",
        "  - `xlsx_file`: Boolean flag indicating whether to save the processed data as an Excel file.\n",
        "  - `graph_image`: Boolean flag indicating whether to save generated plots as images.\n",
        "\n",
        "- **Operation**:\n",
        "  - **Base Directory Setup**: Constructs `base_directory` based on `directory0` and initializes an empty `data_dict` using `create_data_frame`.\n",
        "  - **Timestamp Generation**: Generates a timestamp (`timestamp`) for organizing output directories and files.\n",
        "  - **Directory Iteration**:\n",
        "    - If `directory1` is 'all', iterates over all subdirectories (`dir1`) within `base_directory`.\n",
        "      - Checks if each `dir1` exists and is a directory.\n",
        "      - Iterates over subdirectories (`dir12`) within each `dir1` to construct `xml_directory`.\n",
        "      - Calls `main` function to process XML files in `xml_directory` for each valid directory.\n",
        "    - If `directory2` is 'all', constructs `base_directory2` and iterates over all subdirectories (`dir2`) within it.\n",
        "      - Calls `main` function to process XML files in each valid `xml_directory`.\n",
        "    - Otherwise, directly calls `main` function to process XML files in the specified `directory0`, `directory1`, and `directory2`.\n",
        "  - **Save Data as Excel**: If `xlsx_file` is `True`, creates an output directory (`output_directory`) and saves `data_dict` as an Excel file (`analysis_result.xlsx`) using `save_data_frame`.\n",
        "\n",
        "- **Return Value**: None. The function operates by side effects, processing XML files, generating plots, and saving data as specified.\n"
      ],
      "metadata": {
        "id": "rrYeKyWq2hJe"
      },
      "id": "rrYeKyWq2hJe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXAuCG_q20cn"
      },
      "source": [
        "## **main.py**"
      ],
      "id": "cXAuCG_q20cn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1MZccmA20cn"
      },
      "outputs": [],
      "source": [
        "def main(directory0, directory1, directory2, current_directory, data_dict, testsite, graph_image, timestamp):\n",
        "    xml_files, xml_directory = parse_xml_files(directory0, directory1, directory2, current_directory,testsite)\n",
        "    if xml_files is None:\n",
        "        print(\"Failed to parse XML files. Please check the directory paths and try again.\")\n",
        "        return\n",
        "\n",
        "    for filename, root in xml_files:\n",
        "        voltage_values, abs_current, final, R_squared, current_values = process_iv_data(root)\n",
        "        transmissions = process_transmission_data(root)\n",
        "        reference_wave, reference_trans = extract_reference_data(root)\n",
        "\n",
        "        fig, axs = plt.subplots(2, 4, figsize=(20, 8))\n",
        "\n",
        "        plot_iv(axs[0, 3], voltage_values, abs_current, final, R_squared, current_values)\n",
        "        ref_transmission_point = plot_transmission(axs[0, 0], transmissions)\n",
        "        r_squared_values = {}\n",
        "        polynomial = plot_reference(axs[0, 1], reference_wave, reference_trans, r_squared_values)\n",
        "        wavelength_array, flat_meas_trans = plot_flat_transmission(axs[0, 2], transmissions, polynomial)\n",
        "        make_linear(axs[1, 0], axs[1, 1], axs[1, 2], axs[1, 3], wavelength_array, flat_meas_trans)\n",
        "        data_dict = update_data_frame(data_dict, root, r_squared_values[6], ref_transmission_point, R_squared,\n",
        "                                      current_values, voltage_values, abs_current, transmissions)\n",
        "\n",
        "        filename = filename.replace('.xml', '')\n",
        "        image_output_directory = os.path.join(current_directory, 'res', timestamp, directory0, directory1, directory2)\n",
        "        os.makedirs(image_output_directory, exist_ok=True)\n",
        "        image_filename = f'{filename}.png'\n",
        "        image_path = os.path.join(image_output_directory, image_filename)\n",
        "        file_path = os.path.abspath(image_path).replace('\\\\', '/')\n",
        "        filename_no_ext, _ = os.path.splitext(filename)\n",
        "        if graph_image:\n",
        "            data_dict['Graph Image'].append(f'=HYPERLINK(\"{file_path}\", \"{filename_no_ext}\")')\n",
        "        else:\n",
        "            data_dict['Graph Image'].append('None')\n",
        "\n",
        "        image_path = os.path.join(image_output_directory, f'{filename_no_ext}.png')\n",
        "        plt.suptitle(filename)\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(hspace=0.3)\n",
        "        if graph_image:\n",
        "            plt.savefig(image_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "        print('---', filename, '---')\n"
      ],
      "id": "S1MZccmA20cn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: **main**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Executes a series of data processing and plotting tasks for each XML file found in specified directories.\n",
        "- **Parameters**:\n",
        "  - `directory0`, `directory1`, `directory2`: Subdirectories within `current_directory` where XML files are located.\n",
        "  - `current_directory`: Root directory containing subdirectories where XML files reside.\n",
        "  - `data_dict`: Dictionary storing data to be updated and saved.\n",
        "  - `testsite`: List of test site names used to filter XML files.\n",
        "  - `graph_image`: Boolean flag indicating whether to save generated plots as images.\n",
        "  - `timestamp`: Timestamp used for organizing output images.\n",
        "\n",
        "- **Operation**:\n",
        "  - **Parse XML Files**: Calls `parse_xml_files` function to retrieve XML file paths and their corresponding root elements (`xml_files`).\n",
        "  - **Check for Errors**: If no XML files are found (`xml_files` is `None`), prints an error message and exits.\n",
        "  - **Iterate through XML Files**:\n",
        "    - For each XML file, extracts and processes:\n",
        "      - IV data (`voltage_values`, `abs_current`, `final`, `R_squared`, `current_values`) using `process_iv_data`.\n",
        "      - Transmission data (`transmissions`) using `process_transmission_data`.\n",
        "      - Reference data (`reference_wave`, `reference_trans`) using `extract_reference_data`.\n",
        "      - Generates a subplot figure (`fig, axs`) with multiple plots.\n",
        "      - Plots IV data (`plot_iv`), transmission data (`plot_transmission`), reference data (`plot_reference`), and flat transmission data (`plot_flat_transmission`).\n",
        "      - Updates `data_dict` using `update_data_frame` with processed data.\n",
        "      - Saves plots as images in a specified directory (`image_output_directory`) if `graph_image` is `True`.\n",
        "      - Updates `data_dict['Graph Image']` with hyperlinks to the saved images or marks as 'None' if `graph_image` is `False`.\n",
        "      - Closes the plot figure to release resources (`plt.close(fig)`).\n",
        "      - Prints a message indicating completion of processing for each file (`print('---', filename, '---')`)."
      ],
      "metadata": {
        "id": "a-cgrETJ20cn"
      },
      "id": "a-cgrETJ20cn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **parsing.py**"
      ],
      "metadata": {
        "id": "5PtrBbsi178K"
      },
      "id": "5PtrBbsi178K"
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml_files(directory0, directory1, directory2, current_directory, teststie):\n",
        "    xml_directory = os.path.join(current_directory, 'dat', directory0, directory1, directory2)\n",
        "    if not os.path.isdir(xml_directory):\n",
        "        print(f\"The directory {xml_directory} does not exist. Please enter a valid directory path.\")\n",
        "        return None, None, None\n",
        "\n",
        "    xml_files = []\n",
        "    for filename in os.listdir(xml_directory):\n",
        "        if any(filename.endswith(f'{site}.xml') for site in teststie):\n",
        "            xml_file_path = os.path.join(xml_directory, filename)\n",
        "            tree = eT.parse(xml_file_path)\n",
        "            root = tree.getroot()\n",
        "            xml_files.append((filename, root))\n",
        "\n",
        "    return xml_files, xml_directory\n"
      ],
      "metadata": {
        "id": "HG6WDEzQ178Q"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HG6WDEzQ178Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: parse_xml_files\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Parses XML files located in a specified directory based on given parameters.\n",
        "- **Parameters**:\n",
        "  - `directory0`, `directory1`, `directory2`: Directories leading to the XML files.\n",
        "  - `current_directory`: Current working directory where 'dat' folder is located.\n",
        "  - `teststie`: List of test site names used to filter XML files.\n",
        "- **Returns**:\n",
        "  - `xml_files`: List of tuples containing filenames and corresponding XML roots.\n",
        "  - `xml_directory`: Path to the directory containing the XML files.\n",
        "\n",
        "### Steps\n",
        "1. **XML Directory Construction**:\n",
        "   - Constructs the path to the directory containing XML files based on provided directories and current working directory (`current_directory`).\n",
        "\n",
        "2. **Directory Validation**:\n",
        "   - Checks if the constructed `xml_directory` exists. If not, prints an error message and returns `None`.\n",
        "\n",
        "3. **File Listing and Filtering**:\n",
        "   - Iterates through files in `xml_directory`.\n",
        "   - Filters files based on whether their filenames end with any test site name from `teststie`.\n",
        "   - Parses valid XML files using ElementTree (`eT`) and stores tuples of filename and root in `xml_files`.\n",
        "\n",
        "4. **Return**:\n",
        "   - Returns `xml_files` containing tuples of filename and root for each valid XML file, and `xml_directory` as the path to the directory containing these files.\n"
      ],
      "metadata": {
        "id": "fcDAg50i178Q"
      },
      "id": "fcDAg50i178Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **iv.py**"
      ],
      "metadata": {
        "id": "PMKytGtP1utP"
      },
      "id": "PMKytGtP1utP"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_iv_data(root):\n",
        "    voltage_str = root.find('.//Voltage').text\n",
        "    voltage_values = np.array([float(v) for v in voltage_str.split(',')])\n",
        "    current_str = root.find('.//Current').text\n",
        "    current_values = np.array([float(v) for v in current_str.split(',')])\n",
        "    abs_current = np.abs(current_values)\n",
        "\n",
        "    def mob(params, x, data=None):\n",
        "        Is = params['Is']\n",
        "        Vt = params['Vt']\n",
        "        n = params['n']\n",
        "        if abs_current[0]*1000 > abs_current[12]:\n",
        "            poly_coeff = np.polyfit(x[x < 2], data[x < 2], deg=12)\n",
        "            model_negative = np.polyval(poly_coeff, x[x < 2])\n",
        "            model_positive = Is * (np.exp(x[x >= 2] / (n * Vt)) - 1)\n",
        "            model = np.concatenate((model_negative, model_positive))\n",
        "        else:\n",
        "            poly_coeff = np.polyfit(x[x < 0], data[x < 0], deg=6)\n",
        "            model_negative = np.polyval(poly_coeff, x[x < 0])\n",
        "            model_positive = Is * (np.exp(x[x >= 0] / (n * Vt)) - 1)\n",
        "            model = np.concatenate((model_negative, model_positive))\n",
        "        if data is None:\n",
        "            return model\n",
        "        else:\n",
        "            return model - data\n",
        "\n",
        "    pars = Parameters()\n",
        "    pars.add('Is', value=10 ** -8)\n",
        "    pars.add('Vt', value=0.026)\n",
        "    pars.add('n', value=1, vary=False)\n",
        "\n",
        "    fitter = Minimizer(mob, pars, fcn_args=(voltage_values, current_values))\n",
        "    result = fitter.minimize()\n",
        "    final = abs_current + result.residual\n",
        "\n",
        "    RSS = np.sum(result.residual ** 2)\n",
        "    mean_current = np.mean(current_values)\n",
        "    TSS = np.sum((current_values - mean_current) ** 2)\n",
        "    R_squared = 1 - (Decimal(RSS) / Decimal(TSS))\n",
        "\n",
        "    return voltage_values, abs_current, final, R_squared, current_values\n"
      ],
      "metadata": {
        "id": "bD8xb3Gy1utP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bD8xb3Gy1utP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: process_iv_data\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Processes IV (Current-Voltage) data extracted from XML `root`, fits a model, and computes statistical metrics.\n",
        "- **Parameters**:\n",
        "  - `root`: XML root element containing the data.\n",
        "- **Returns**:\n",
        "  - `voltage_values`: Array of voltage values extracted from XML.\n",
        "  - `abs_current`: Array of absolute current values extracted from XML.\n",
        "  - `final`: Array of modeled current values after fitting.\n",
        "  - `R_squared`: R-squared value indicating the goodness of fit.\n",
        "  - `current_values`: Array of original current values extracted from XML."
      ],
      "metadata": {
        "id": "MNQ2IFNP1utP"
      },
      "id": "MNQ2IFNP1utP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **transmission.py**"
      ],
      "metadata": {
        "id": "QZdMlYUc2A23"
      },
      "id": "QZdMlYUc2A23"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_transmission_data(root):\n",
        "    wavelength_sweeps = root.findall('.//WavelengthSweep')\n",
        "    transmissions = []\n",
        "\n",
        "    for wavelengthsweep in wavelength_sweeps:\n",
        "        dc_bias = float(wavelengthsweep.get('DCBias'))\n",
        "        wavelength_str = wavelengthsweep.find('.//L').text\n",
        "        transmission_str = wavelengthsweep.find('.//IL').text\n",
        "        wavelength_list = [float(w) for w in wavelength_str.split(',')]\n",
        "        transmission_list = [float(t) for t in transmission_str.split(',')]\n",
        "        transmissions.append((dc_bias, wavelength_list, transmission_list))\n",
        "\n",
        "    return transmissions\n"
      ],
      "metadata": {
        "id": "bhTT2YiZ2A29"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bhTT2YiZ2A29"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: process_transmission_data\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Processes transmission data extracted from XML `root` containing multiple wavelength sweeps.\n",
        "- **Parameters**:\n",
        "  - `root`: XML root element containing the data.\n",
        "- **Returns**:\n",
        "  - `transmissions`: List of tuples, each containing DC bias and corresponding wavelength and transmission lists.\n",
        "\n",
        "### Function Details\n",
        "- **Data Extraction**:\n",
        "  - Finds all `WavelengthSweep` elements in the XML root (`root`).\n",
        "\n",
        "- **Iteration**:\n",
        "  - Iterates through each `WavelengthSweep` to extract DC bias, wavelength, and transmission data.\n",
        "\n",
        "- **Data Conversion**:\n",
        "  - Converts extracted wavelength and transmission strings into lists of floating-point numbers (`wavelength_list` and `transmission_list`).\n",
        "\n",
        "- **Data Structure**:\n",
        "  - Constructs tuples for each wavelength sweep containing DC bias, `wavelength_list`, and `transmission_list`.\n",
        "\n",
        "- **Return**:\n",
        "  - Returns `transmissions`, a list of tuples where each tuple represents data from one `WavelengthSweep`.\n"
      ],
      "metadata": {
        "id": "vykqUDaa2A29"
      },
      "id": "vykqUDaa2A29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpXJF6A23MPt"
      },
      "source": [
        "## **reference.py**"
      ],
      "id": "qpXJF6A23MPt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHXfMAR_3MPz"
      },
      "outputs": [],
      "source": [
        "def extract_reference_data(root):\n",
        "    reference_wave = []\n",
        "    reference_trans = []\n",
        "    for wavelengthsweep in root.findall('.//WavelengthSweep'):\n",
        "        wavelength_str = wavelengthsweep.find('.//L').text\n",
        "        transmission_str = wavelengthsweep.find('.//IL').text\n",
        "        wavelength_list = [float(w) for w in wavelength_str.split(',')]\n",
        "        transmission_list = [float(t) for t in transmission_str.split(',')]\n",
        "        reference_wave = wavelength_list\n",
        "        reference_trans = transmission_list\n",
        "    return reference_wave, reference_trans\n"
      ],
      "id": "zHXfMAR_3MPz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: extract_reference_data\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Extracts wavelength and transmission data from XML `root` containing multiple 'WavelengthSweep' elements.\n",
        "- **Parameters**:\n",
        "  - `root`: XML root element containing the data.\n",
        "- **Returns**:\n",
        "  - `reference_wave`: List of extracted wavelength values.\n",
        "  - `reference_trans`: List of corresponding transmission values.\n",
        "\n",
        "### Steps\n",
        "1. **Initialization**:\n",
        "   - Initializes empty lists `reference_wave` and `reference_trans` to store extracted data.\n",
        "\n",
        "2. **Data Extraction Loop**:\n",
        "   - Iterates through each 'WavelengthSweep' element found in the XML structure under `root`.\n",
        "   - Finds the 'L' (wavelength) and 'IL' (transmission) elements within each 'WavelengthSweep'.\n",
        "\n",
        "3. **Data Parsing**:\n",
        "   - Extracts text content from 'L' and 'IL' elements as strings.\n",
        "   - Splits these strings by commas to convert into lists of floating-point numbers (`wavelength_list` and `transmission_list`).\n",
        "\n",
        "4. **Assignment**:\n",
        "   - Assigns the extracted lists to `reference_wave` and `reference_trans` respectively.\n",
        "\n",
        "5. **Return**:\n",
        "   - Returns `reference_wave` and `reference_trans` containing all extracted wavelength and transmission data."
      ],
      "metadata": {
        "id": "yNgVLTHT3MPz"
      },
      "id": "yNgVLTHT3MPz"
    },
    {
      "cell_type": "markdown",
      "id": "c39da0a5",
      "metadata": {
        "id": "c39da0a5"
      },
      "source": [
        "## **plot.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f289dc5c",
      "metadata": {
        "id": "f289dc5c"
      },
      "outputs": [],
      "source": [
        "def plot_iv(ax, voltage_values, abs_current, final, R_squared, current_values):\n",
        "    def log_formatter(x, pos):\n",
        "        return \"{:.0e}\".format(x)\n",
        "\n",
        "    y_text_position = 1e-5 if abs_current.max() >= 1e-3 and abs_current.min() <= 1e-10 else (\n",
        "        1e-10 if abs_current.max() <= 2e-10 and abs_current.min() >= 6e-11 else min(abs_current) * 1.5)\n",
        "\n",
        "    ax.scatter(voltage_values, abs_current, label='data')\n",
        "    ax.plot(voltage_values, final, 'r-', label=f'fit (R²: {R_squared:.4f})')\n",
        "    ax.set_xlim(-2, 1)\n",
        "    ax.set_yscale('log')\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(log_formatter))\n",
        "    ax.set_title('IV raw data & fitted data (log scale)')\n",
        "    ax.set_ylabel('Absolute Current (A)')\n",
        "    ax.set_xlabel('Voltage (V)')\n",
        "    ax.grid(True)\n",
        "    ax.legend(loc='upper left')\n",
        "    ax.text(-1.9, y_text_position,\n",
        "            f'  R²: {R_squared}\\n-2V: {current_values[0]:.2e}\\n-1V: {current_values[4]:.2e} \\n 1V: {current_values[12]:.2e}',\n",
        "            fontsize=10, horizontalalignment='left', verticalalignment='center')\n",
        "\n",
        "\n",
        "def plot_transmission(ax, transmissions):\n",
        "    ref_transmission_point = -50\n",
        "    for i, (dc_bias, wavelength_list, transmission_list) in enumerate(transmissions):\n",
        "        label = None if i == len(transmissions) - 1 else f'{dc_bias}V'\n",
        "        ax.plot(wavelength_list, transmission_list, label=label)\n",
        "        if i == len(transmissions) - 1:\n",
        "            peaks, _ = find_peaks(transmission_list, distance=50)\n",
        "            for peak_index in peaks:\n",
        "                if transmission_list[peak_index] > ref_transmission_point:\n",
        "                    ref_transmission_point = transmission_list[peak_index]\n",
        "\n",
        "    ax.set_xlabel('Wavelength (nm)')\n",
        "    ax.set_ylabel('Transmission (dB)')\n",
        "    ax.set_title('Transmission vs Wavelength')\n",
        "    ax.grid(True)\n",
        "    ax.legend(loc='lower right', bbox_to_anchor=(1.3, 0.47))\n",
        "\n",
        "    return ref_transmission_point\n",
        "\n",
        "\n",
        "def plot_reference(ax, reference_wave, reference_trans, r_squared_values):\n",
        "    ax.plot(reference_wave, reference_trans, label='data')\n",
        "    degrees = range(1, 7)\n",
        "    max_transmission = np.max(reference_trans)\n",
        "    min_transmission = np.min(reference_trans)\n",
        "    y_pos = 0.5 * (max_transmission + min_transmission) - 0.3\n",
        "    x_pos = reference_wave[0] + 0.5 * (reference_wave[-1] - reference_wave[0])\n",
        "    best_r = 0\n",
        "    for degree in degrees:\n",
        "        coeffs, _, _, _ = np.linalg.lstsq(np.vander(reference_wave, degree + 1), reference_trans, rcond=None)\n",
        "        polynomial1 = np.poly1d(coeffs)\n",
        "        ax.plot(reference_wave, polynomial1(reference_wave), label=f'{degree}th')\n",
        "        mean_transmission = np.mean(reference_trans)\n",
        "        total_variation = np.sum((reference_trans - mean_transmission) ** 2)\n",
        "        residuals = np.sum((reference_trans - polynomial1(reference_wave)) ** 2)\n",
        "        r_squared = 1 - (residuals / total_variation)\n",
        "        r_squared_values[degree] = r_squared\n",
        "        ax.text(x_pos, y_pos, f'{degree}th R²: {r_squared:.4f}', fontsize=10, verticalalignment='center',\n",
        "                horizontalalignment='center')\n",
        "        y_pos -= 0.06 * (max_transmission - min_transmission)\n",
        "        if best_r<=r_squared:\n",
        "            best_r = r_squared\n",
        "            polynomial = polynomial1\n",
        "\n",
        "        ax.set_xlabel('Wavelength (nm)')\n",
        "        ax.set_ylabel('Transmission (dB)')\n",
        "        ax.set_title('Reference Transmission')\n",
        "        ax.grid(True)\n",
        "        ax.legend(loc='lower right', bbox_to_anchor=(1.3, 0.47))\n",
        "\n",
        "    return polynomial\n",
        "\n",
        "\n",
        "def plot_flat_transmission(ax, transmissions, polynomial):\n",
        "    mid_transmission = (min(transmissions[0][1]) + max(transmissions[0][1])) / 2\n",
        "    max_transmission_point, max_transmission_point2 = -50, -50\n",
        "\n",
        "    wavelength = []\n",
        "    flat_trans = []\n",
        "\n",
        "    for i, (dc_bias, wavelength_list, transmission_list) in enumerate(transmissions):\n",
        "        flat_transmission = np.array(transmission_list) - np.array(polynomial(wavelength_list))\n",
        "        if i != len(transmissions) - 1:\n",
        "            peaks, _ = find_peaks(flat_transmission, distance=50)\n",
        "            for peak_index in peaks:\n",
        "                if min(wavelength_list) <= wavelength_list[peak_index] <= mid_transmission:\n",
        "                    if flat_transmission[peak_index] > max_transmission_point:\n",
        "                        max_transmission_point = flat_transmission[peak_index]\n",
        "                        max_transmission_wavelength = wavelength_list[peak_index]\n",
        "                if mid_transmission <= wavelength_list[peak_index] <= max(wavelength_list):\n",
        "                    if flat_transmission[peak_index] > max_transmission_point2:\n",
        "                        max_transmission_point2 = flat_transmission[peak_index]\n",
        "                        max_transmission_wavelength2 = wavelength_list[peak_index]\n",
        "\n",
        "    m = (max_transmission_point2 - max_transmission_point) / (\n",
        "                max_transmission_wavelength2 - max_transmission_wavelength)\n",
        "    b = max_transmission_point - m * max_transmission_wavelength\n",
        "    peak_fit = m * np.array(transmissions[0][1]) + b\n",
        "\n",
        "\n",
        "    for i, (dc_bias, wavelength_list, transmission_list) in enumerate(transmissions):\n",
        "        poly_wavelength_array, peak_fit = lm.match_array_lengths(np.array(polynomial(wavelength_list)), peak_fit)\n",
        "        transmission_array, peak_fit = lm.match_array_lengths(np.array(transmission_list), peak_fit)\n",
        "        flat_meas_trans = transmission_array - poly_wavelength_array - (peak_fit if i != len(transmissions) - 1 else 0)\n",
        "        wavelength_array, flat_meas_trans = lm.match_array_lengths( np.array(wavelength_list), flat_meas_trans)\n",
        "        ax.plot(wavelength_array, flat_meas_trans, label=f'{dc_bias}V' if i != len(transmissions) - 1 else None)\n",
        "        wavelength.append(wavelength_array)\n",
        "        flat_trans.append(flat_meas_trans)\n",
        "\n",
        "    wavelength = lm.trim_lists_to_min_length(wavelength)\n",
        "    flat_trans = lm.trim_lists_to_min_length(flat_trans)\n",
        "    wavelength = np.array(wavelength)\n",
        "    flat_trans = np.array(flat_trans)\n",
        "\n",
        "    ax.set_xlabel('Wavelength (nm)')\n",
        "    ax.set_ylabel('Flat Measured Transmission (dB)')\n",
        "    ax.set_title('Flat Transmission spectra - as measured')\n",
        "    ax.grid(True)\n",
        "    ax.legend(loc='lower right', bbox_to_anchor=(1.3, 0.47))\n",
        "\n",
        "    return wavelength, flat_trans"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: **plot_iv**\n",
        "\n",
        "### Explanation\n",
        "- **log_formatter**: Custom function to format y-axis labels in scientific notation.\n",
        "- **y_text_position**: Determines y-axis text position based on the range of `abs_current`.\n",
        "- **Plotting**:\n",
        "  - Scatter plot of `voltage_values` vs. `abs_current`.\n",
        "  - Line plot of `voltage_values` vs. `final` (fitted data) with R-squared value in the legend.\n",
        "  - Logarithmic y-axis and grid.\n",
        "  - Adds labels, title, and custom text for specific current values.\n",
        "---\n",
        "## Function: **plot_transmission**\n",
        "\n",
        "### Explanation\n",
        "- **Plotting**: Plots transmission data (`wavelength_list` vs. `transmission_list`) for each bias voltage.\n",
        "- **Peak Detection**: Finds peaks in the transmission data for the last transmission list to determine `ref_transmission_point`.\n",
        "- **Labels and Grid**: Adds labels, title, legend, and grid to the plot.\n",
        "---\n",
        "## Function: **plot_reference**\n",
        "\n",
        "### Explanation\n",
        "- **Plotting**: Plots reference transmission data and polynomial fits for degrees 1 through 6.\n",
        "- **R-Squared Calculation**: Computes R-squared values for each polynomial fit and updates `r_squared_values`.\n",
        "- **Labels and Grid**: Adds labels, title, legend, and grid to the plot. Annotates the plot with R-squared values.\n",
        "---\n",
        "## Function: **plot_flat_transmission**\n",
        "\n",
        "### Explanation\n",
        "- **Flat Transmission Calculation**: Computes flat transmission spectra by subtracting the polynomial fit from the transmission data.\n",
        "- **Peak Detection**: Finds peaks in the flat transmission data to determine the best fit line.\n",
        "- **Linear Fit**: Computes and applies a linear fit to the data.\n",
        "- **Plotting**: Plots flat transmission spectra for each bias voltage.\n",
        "- **Labels and Grid**: Adds labels, title, legend, and grid to the plot.\n",
        "---\n",
        "## Summary of the Entire Code\n",
        "1. **plot_iv Function**: Plots IV data on a log scale with fitted data and relevant annotations.\n",
        "2. **plot_transmission Function**: Plots transmission data vs. wavelength and finds the peak transmission point.\n",
        "3. **plot_reference Function**: Plots reference transmission data with polynomial fits and calculates R-squared values for each fit.\n",
        "4. **plot_flat_transmission Function**: Computes and plots flat transmission spectra by removing polynomial fits from transmission data and applies a linear fit to the peaks.\n",
        "\n"
      ],
      "metadata": {
        "id": "n9A5iOCUcK1o"
      },
      "id": "n9A5iOCUcK1o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **linear.py**"
      ],
      "metadata": {
        "id": "fsYp4y5SMQ37"
      },
      "id": "fsYp4y5SMQ37"
    },
    {
      "cell_type": "code",
      "source": [
        "def r_squared(y_true, y_pred):\n",
        "    y_mean = np.mean(y_true)\n",
        "    tss = np.sum((y_true - y_mean) ** 2)\n",
        "    rss = np.sum((y_true - y_pred) ** 2)\n",
        "    if tss == 0:\n",
        "        return 1 if rss == 0 else 0\n",
        "    r2 = 1 - (Decimal(rss) / Decimal(tss))\n",
        "    return r2\n",
        "\n",
        "# ax1: data-linear, ax2: fitting, ax3: fitting_all, ax4: delta neff\n",
        "def make_linear(ax1, ax2, ax3, ax4, wavelength_array, flat_meas_trans):\n",
        "\n",
        "    r2_linear = []\n",
        "\n",
        "    linear_minus_2 = 10 ** (flat_meas_trans[0] / 10) * 0.0005\n",
        "    linear_minus_1_dot_5 = 10 ** (flat_meas_trans[1] / 10) * 0.0005\n",
        "    linear_minus_1 = 10 ** (flat_meas_trans[2] / 10) * 0.0005\n",
        "    linear_minus_0_dot_5 = 10 ** (flat_meas_trans[3] / 10) * 0.0005\n",
        "    linear_0 = 10 ** (flat_meas_trans[4] / 10) * 0.0005\n",
        "    linear_0_dot_5 = 10 ** (flat_meas_trans[5] / 10) * 0.0005\n",
        "\n",
        "    ax1.plot(wavelength_array[0], linear_minus_2, label='-2.0V')\n",
        "    ax1.plot(wavelength_array[1], linear_minus_1_dot_5, label='-1.5V')\n",
        "    ax1.plot(wavelength_array[2], linear_minus_1, label='-1.0V')\n",
        "    ax1.plot(wavelength_array[3], linear_minus_0_dot_5, label='-0.5V')\n",
        "    ax1.plot(wavelength_array[4], linear_0, label='0.0V')\n",
        "    ax1.plot(wavelength_array[5], linear_0_dot_5, label='0.5V')\n",
        "    ax1.set_xlabel('Wavelength (nm)')\n",
        "    ax1.set_ylabel('Intensity (W/m^2)')\n",
        "    ax1.set_title('Flat transmission spectra - linear')\n",
        "    ax1.grid(True)\n",
        "    ax1.legend(loc='lower right', bbox_to_anchor=(1.3, 0.47))\n",
        "\n",
        "    def intensity(lamda, neff, delta, l, deltaL, I0):\n",
        "        I = I0 * np.sin(((2 * np.pi / lamda) * deltaL * neff) / 2 + ((2 * np.pi / lamda) * l * delta / 2)) ** 2\n",
        "        return I\n",
        "\n",
        "    model = Model(intensity)\n",
        "\n",
        "\n",
        "    params = model.make_params(neff=4.1, delta=0, l=500 * (10 ** -6), deltaL=40 * (10 ** -6), I0=0.0005)\n",
        "    params['delta'].vary = False\n",
        "    params['l'].vary = False\n",
        "    params['deltaL'].vary = False\n",
        "    params['I0'].vary = False\n",
        "    params['neff'].vary = True\n",
        "\n",
        "    x_nm = wavelength_array * (10 ** -9)\n",
        "\n",
        "    result = model.fit(linear_0, params, lamda=x_nm[4])\n",
        "\n",
        "    r2_2 = r_squared(linear_0, result.best_fit)\n",
        "    neff_value = result.params['neff'].value\n",
        "\n",
        "\n",
        "    ax2.scatter(wavelength_array[4], linear_0, s=5, label='data')\n",
        "    ax2.plot(wavelength_array[4], result.best_fit, label='fit', color='red')\n",
        "    ax2.set_xlabel('Wavelength (nm)')\n",
        "    ax2.set_ylabel('Intensity (W/m^2)')\n",
        "    ax2.set_title('Flat transmission spectra - fitted 0.0V')\n",
        "    ax2.grid(True)\n",
        "    ax2.legend(loc='lower right', bbox_to_anchor=(1.3, 0.47))\n",
        "\n",
        "    delta_n = []\n",
        "\n",
        "    model2 = Model(intensity)\n",
        "\n",
        "    params = model2.make_params(neff=neff_value, delta=0, l=500 * (10 ** -6), deltaL=40 * (10 ** -6), I0=0.0005)\n",
        "    params['delta'].vary = True\n",
        "    params['l'].vary = False\n",
        "    params['deltaL'].vary = False\n",
        "    params['I0'].vary = False\n",
        "    params['neff'].vary = False\n",
        "\n",
        "    # -2V\n",
        "    result2 = model2.fit(linear_minus_2, params, lamda=x_nm[0])\n",
        "    r2_3 = r_squared(linear_minus_2, result2.best_fit)\n",
        "    delta_neff_value = result2.params['delta'].value\n",
        "    delta_n.append(delta_neff_value)\n",
        "\n",
        "    # -1.5V\n",
        "    result3 = model2.fit(linear_minus_1_dot_5, params, lamda=x_nm[1])\n",
        "    r2_4 = r_squared(linear_minus_1_dot_5, result3.best_fit)\n",
        "    delta_neff_value = result3.params['delta'].value\n",
        "    delta_n.append(delta_neff_value)\n",
        "\n",
        "    # -1V\n",
        "    result4 = model2.fit(linear_minus_1, params, lamda=x_nm[2])\n",
        "    r2_5 = r_squared(linear_minus_1, result4.best_fit)\n",
        "    delta_neff_value = result4.params['delta'].value\n",
        "    delta_n.append(delta_neff_value)\n",
        "\n",
        "    # -0.5V\n",
        "    result5 = model2.fit(linear_minus_0_dot_5, params, lamda=x_nm[3])\n",
        "    r2_6 = r_squared(linear_minus_0_dot_5, result5.best_fit)\n",
        "    delta_neff_value = result5.params['delta'].value\n",
        "    delta_n.append(delta_neff_value)\n",
        "\n",
        "    # 0V\n",
        "    result6 = model2.fit(linear_0, params, lamda=x_nm[3])\n",
        "    r2_7 = r_squared(linear_0, result6.best_fit)\n",
        "    delta_neff_value = result6.params['delta'].value\n",
        "    delta_n.append(delta_neff_value)\n",
        "\n",
        "    # 0.5V\n",
        "    result7 = model2.fit(linear_0_dot_5, params, lamda=x_nm[5])\n",
        "    r2_8 = r_squared(linear_0_dot_5, result7.best_fit)\n",
        "    delta_neff_value = result7.params['delta'].value\n",
        "    delta_n.append(delta_neff_value)\n",
        "\n",
        "    ax3.plot(wavelength_array[0], result2.best_fit, label='-2.0V')\n",
        "    ax3.plot(wavelength_array[1], result3.best_fit, label='-1.5V')\n",
        "    ax3.plot(wavelength_array[2], result4.best_fit, label='-1.0V')\n",
        "    ax3.plot(wavelength_array[3], result5.best_fit, label='-0.5V')\n",
        "    ax3.plot(wavelength_array[4], result6.best_fit, label='0.0V')\n",
        "    ax3.plot(wavelength_array[5], result7.best_fit, label='0.5V')\n",
        "\n",
        "    ax3.set_xlabel('Wavelength (nm)')\n",
        "    ax3.set_ylabel('Intensity (W/m^2)')\n",
        "    ax3.set_title('Flat transmission spectra - fitted')\n",
        "    ax3.grid(True)\n",
        "    ax3.legend(loc='lower right', bbox_to_anchor=(1.3, 0.47))\n",
        "\n",
        "    voltage = [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5]\n",
        "    x = np.arange(len(delta_n))\n",
        "    coefficients = np.polyfit(x, delta_n, 2)\n",
        "    polynomial = np.poly1d(coefficients)\n",
        "    y_fit = polynomial(x)\n",
        "    r2=r_squared(delta_n,y_fit)\n",
        "\n",
        "    ax4.scatter(voltage, delta_n, label='delta')\n",
        "    ax4.plot(voltage, y_fit, 'r-', label=f'fit (R²: {r2:.4f})')\n",
        "    ax4.set_xlabel('Voltage(V)')\n",
        "    ax4.set_ylabel('delta_n')\n",
        "    ax4.set_title('Delta n_eff')\n",
        "    ax4.grid(True)\n",
        "    ax4.legend(loc='upper right')\n",
        "\n",
        "    r2_linear.append(r2_2)      # fitted 0V\n",
        "    r2_linear.append(r2_3)      # -2V\n",
        "    r2_linear.append(r2_4)      # -1.5V\n",
        "    r2_linear.append(r2_5)      # -1V\n",
        "    r2_linear.append(r2_6)      # -0.5V\n",
        "    r2_linear.append(r2_7)      # 0V\n",
        "    r2_linear.append(r2_8)      # 0.5V\n",
        "\n",
        "    return r2_linear\n"
      ],
      "metadata": {
        "id": "Mlw34KglMQp0"
      },
      "id": "Mlw34KglMQp0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: r_squared\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Calculates the R-squared value to determine the goodness of fit for a model.\n",
        "- **Parameters**:\n",
        "  - `y_true`: The true values of the dependent variable.\n",
        "  - `y_pred`: The predicted values from the model.\n",
        "- **Calculations**:\n",
        "  - `y_mean`: The mean of the true values.\n",
        "  - `tss`: Total sum of squares, representing the variance of the data.\n",
        "  - `rss`: Residual sum of squares, representing the variance of the residuals.\n",
        "  - R-squared is calculated as \\( R^2 = 1 - \\frac{rss}{tss} \\).\n",
        "- **Return Value**: The R-squared value, a measure of how well the model fits the data.\n",
        "---\n",
        "## Function: make_linear\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Processes measurement data, fits models to it, and plots the results.\n",
        "- **Parameters**:\n",
        "  - `ax1`, `ax2`, `ax3`, `ax4`: Axes objects for plotting.\n",
        "  - `wavelength_array`: Array of wavelength values.\n",
        "  - `flat_meas_trans`: Array of flat measurement transmission data.\n",
        "- **Steps**:\n",
        "  1. Converts transmission data to linear scale.\n",
        "  2. Plots the transmission spectra.\n",
        "  3. Defines an intensity function model.\n",
        "  4. Fits the model to the data for 0.0V to find `neff`.\n",
        "  5. Calculates and plots the best fit for 0.0V.\n",
        "  6. Fits the model for other voltage values (-2.0V to 0.5V) to find `delta_n`.\n",
        "  7. Plots the fitted spectra for all voltages.\n",
        "  8. Plots `delta_n` vs voltage and fits a polynomial to it.\n",
        "- **Return Value**: A list of R-squared values for the fits.\n",
        "\n",
        "### Summary\n",
        "1. **r_squared Function**: Calculates the R-squared value for model evaluation.\n",
        "2. **make_linear Function**: Processes and analyzes measurement data, fits models, and plots results.\n"
      ],
      "metadata": {
        "id": "T2bb5NZsMQSs"
      },
      "id": "T2bb5NZsMQSs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfC66HN53Wa5"
      },
      "source": [
        "## **data_frame.py**"
      ],
      "id": "jfC66HN53Wa5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuI6v3NF3Wa_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_data_frame():\n",
        "    data_dict = {key: [] for key in\n",
        "                 ['Lot', 'Wafer', 'Mask', 'TestSite', 'Name', 'Date', 'Script ID', 'Script Version',\n",
        "                  'Script Owner', 'Operator', 'Row', 'Column', 'ErrorFlag', 'Error description', 'Analysis Wavelength',\n",
        "                  'Rsq of Ref. spectrum (Nth)', 'Max transmission of Ref. spec. (dB)', 'Rsq of IV', 'I at -1V [A]',\n",
        "                  'I at 1V [A]', 'Graph Image']}\n",
        "    return data_dict\n",
        "\n",
        "def update_data_frame(data_dict, root, r_squared, ref_transmission_point, R_squared, current_values, voltage_values, abs_current, transmissions):\n",
        "    test_site_info = root.find('.//TestSiteInfo')\n",
        "    data_dict['Lot'].append(test_site_info.get('Batch'))\n",
        "    data_dict['Wafer'].append(test_site_info.get('Wafer'))\n",
        "    data_dict['Mask'].append(test_site_info.get('Maskset'))\n",
        "    data_dict['TestSite'].append(test_site_info.get('TestSite'))\n",
        "\n",
        "    data_dict['Operator'].append(root.get('Operator'))\n",
        "\n",
        "    modulator = root.find('.//ElectroOpticalMeasurements/ModulatorSite/Modulator')\n",
        "    data_dict['Name'].append(modulator.get('Name'))\n",
        "\n",
        "    data_dict['Script ID'].append('process LMZ')\n",
        "    data_dict['Script Version'].append('0.1')\n",
        "    data_dict['Script Owner'].append('A2')\n",
        "\n",
        "    date_stamp = root.find('.//PortCombo').get('DateStamp')\n",
        "    data_dict['Date'].append(date_stamp)\n",
        "\n",
        "    data_dict['Row'].append(test_site_info.get('DieRow'))\n",
        "    data_dict['Column'].append(test_site_info.get('DieColumn'))\n",
        "\n",
        "    if float(r_squared) < 0.95:\n",
        "        data_dict['ErrorFlag'].append('1')\n",
        "        data_dict['Error description'].append('Ref. spec. Error')\n",
        "    elif abs(current_values[0])*1000 > abs(current_values[12]):\n",
        "        data_dict['ErrorFlag'].append('2')\n",
        "        data_dict['Error description'].append('IV. Error')\n",
        "    else:\n",
        "        data_dict['ErrorFlag'].append('0')\n",
        "        data_dict['Error description'].append('No Error')\n",
        "\n",
        "    data_dict['Analysis Wavelength'].append(int(transmissions[0][1][0]))\n",
        "\n",
        "    data_dict['Rsq of Ref. spectrum (Nth)'].append(format(float(r_squared), '.4f'))\n",
        "    data_dict['Max transmission of Ref. spec. (dB)'].append(format(float(ref_transmission_point), '.4f'))\n",
        "    data_dict['Rsq of IV'].append(format(float(R_squared), '.4f'))\n",
        "\n",
        "    i_at_minus_1v = None\n",
        "    i_at_1v = None\n",
        "    for voltage, current in zip(voltage_values, abs_current):\n",
        "        if voltage == -1:\n",
        "            i_at_minus_1v = '{:.4e}'.format(float(current))\n",
        "        elif voltage == 1:\n",
        "            i_at_1v = '{:.4e}'.format(float(current))\n",
        "\n",
        "    data_dict['I at -1V [A]'].append(i_at_minus_1v)\n",
        "    data_dict['I at 1V [A]'].append(i_at_1v)\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "def save_data_frame(data_dict, xlsx_file_path):\n",
        "    df = pd.DataFrame(data_dict)\n",
        "\n",
        "    error_counts = df[df['ErrorFlag'] != '0'].groupby(['Wafer', 'TestSite'])['ErrorFlag'].count()\n",
        "\n",
        "    total_counts_all = df.groupby(['Wafer', 'TestSite'])['ErrorFlag'].count()\n",
        "\n",
        "    error_descriptions = df[df['ErrorFlag'] != '0'].groupby(['Wafer', 'TestSite', 'Error description']).size()\n",
        "\n",
        "    # Create a summary DataFrame\n",
        "    summary_df = pd.DataFrame({\n",
        "        'Total Errors': error_counts,\n",
        "        'Total Entries': total_counts_all,\n",
        "\n",
        "    }).reset_index()\n",
        "\n",
        "    errors_only_df = df[df['ErrorFlag'] != '0']\n",
        "\n",
        "    with pd.ExcelWriter(xlsx_file_path, engine='openpyxl') as writer:\n",
        "        df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
        "\n",
        "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "        error_descriptions = error_descriptions.reset_index(name='Count')\n",
        "        error_descriptions.to_excel(writer, sheet_name='Error Descriptions', index=False)\n",
        "\n",
        "        errors_only_df.to_excel(writer, sheet_name='Errors Only', index=False)\n"
      ],
      "id": "YuI6v3NF3Wa_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: **create_data_frame**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Initializes an empty dictionary with specific keys representing data columns.\n",
        "- **data_dict**: Dictionary with keys representing data columns and empty lists as values.\n",
        "- **Keys**:\n",
        "  - 'Lot', 'Wafer', 'Mask', 'TestSite', 'Name', 'Date', 'Script ID', 'Script Version', 'Script Owner', 'Operator', 'Row', 'Column', 'ErrorFlag', 'Error description', 'Analysis Wavelength', 'Rsq of Ref. spectrum (Nth)', 'Max transmission of Ref. spec. (dB)', 'Rsq of IV', 'I at -1V [A]', 'I at 1V [A]', 'Graph Image'\n",
        "- **Return Value**: The initialized `data_dict`.\n",
        "---\n",
        "## Function: **update_data_frame**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Updates the `data_dict` with data extracted from the XML `root` and calculated values.\n",
        "- **Parameters**:\n",
        "  - `data_dict`: Dictionary to be updated.\n",
        "  - `root`: XML root element containing the data.\n",
        "  - `r_squared`: R-squared value for the reference spectrum.\n",
        "  - `ref_transmission_point`: Maximum transmission point of the reference spectrum.\n",
        "  - `R_squared`: R-squared value for the IV data.\n",
        "  - `current_values`: List of current values at different voltages.\n",
        "  - `voltage_values`: List of voltage values.\n",
        "  - `abs_current`: List of absolute current values.\n",
        "  - `transmissions`: List of transmission data.\n",
        "\n",
        "- **Error Flag and Description**:\n",
        "  - Sets error flag and description based on conditions involving `r_squared` and `current_values`.\n",
        "---\n",
        "## Function: **save_data_frame**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Saves the `data_dict` as an Excel file.\n",
        "- **Parameters**:\n",
        "  - `data_dict`: Dictionary containing the data to be saved.\n",
        "  - `xlsx_file_path`: Path to the output Excel file.\n",
        "\n",
        "- **Conversion**: Converts `data_dict` to a pandas DataFrame.\n",
        "- **Error Handling:**\n",
        "  - Calculates error counts and total entries per wafer and test site.\n",
        "  - Groups error descriptions by wafer, test site, and description.\n",
        "  - Creates a summary DataFrame and writes it to a separate sheet named 'Summary'.\n",
        "  - Writes error descriptions to a sheet named 'Error Descriptions'.\n",
        "  - Writes a filtered DataFrame containing only error entries to a sheet named 'Errors Only'.\n",
        "- **Saving**:\n",
        "  - Uses `ExcelWriter` from `openpyxl` engine to write the DataFrame to an Excel file.\n",
        "  - Writes the DataFrame to `Sheet1` of the Excel file without including the index.\n",
        "\n",
        "---\n",
        "### Summary\n",
        "1. **create_data_frame Function**: Initializes a dictionary with specific keys and empty lists for storing data.\n",
        "2. **update_data_frame Function**: Updates the dictionary with data extracted from XML and calculated values.\n",
        "3. **save_data_frame Function**: Saves the updated dictionary as an Excel file.\n",
        "\n"
      ],
      "metadata": {
        "id": "xlNkHemG3Wa_"
      },
      "id": "xlNkHemG3Wa_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **list_match.py**\n"
      ],
      "metadata": {
        "id": "WbDOtC9v2svM"
      },
      "id": "WbDOtC9v2svM"
    },
    {
      "cell_type": "code",
      "source": [
        "def match_array_lengths(arr1, arr2):\n",
        "\n",
        "    min_length = min(len(arr1), len(arr2))\n",
        "\n",
        "    arr1 = arr1[:min_length]\n",
        "    arr2 = arr2[:min_length]\n",
        "\n",
        "    return arr1, arr2\n",
        "\n",
        "\n",
        "def trim_lists_to_min_length(nested_lists):\n",
        "\n",
        "    min_length = min(len(lst) for lst in nested_lists)\n",
        "\n",
        "    trimmed_lists = [lst[:min_length] for lst in nested_lists]\n",
        "\n",
        "    return trimmed_lists\n",
        "\n"
      ],
      "metadata": {
        "id": "MzGrpMX82svS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MzGrpMX82svS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: **match_array_lengths**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Ensures two arrays have the same length by trimming them to the length of the shorter array.\n",
        "- **Operation**:\n",
        "  - **min_length**: Finds the minimum length between the two arrays.\n",
        "  - Trims both arrays to the `min_length`.\n",
        "---\n",
        "## Function: **trim_lists_to_min_length**\n",
        "\n",
        "### Explanation\n",
        "- **Purpose**: Trims each list in a list of lists to the length of the shortest list.\n",
        "- **Parameters**:\n",
        "  - `nested_lists`: A list containing multiple lists of varying lengths.\n",
        "- **Operation**:\n",
        "  - **min_length**: Determines the length of the shortest list within `nested_lists`.\n",
        "  - **trimmed_lists**: Trims each list in `nested_lists` to the `min_length`.\n",
        "- **Return Value**: A list of lists, each trimmed to the length of the shortest list.\n",
        "\n",
        "### Summary\n",
        "1. **match_array_lengths Function**: Trims two arrays to the length of the shorter one, ensuring they have the same length.\n",
        "2. **trim_lists_to_min_length Function**: Trims each list within a list of lists to the length of the shortest list among them.\n"
      ],
      "metadata": {
        "id": "OJuY4XUR2svT"
      },
      "id": "OJuY4XUR2svT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Result analysis**  <a id=\"result-analysis\"></a>\n",
        "![Graph Photo Example](./needed/graph.png)\n",
        "![Data frame Example](./needed/frame.png)"
      ],
      "metadata": {
        "id": "62KVgGt6efbi"
      },
      "id": "62KVgGt6efbi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is a heatmap of the maximum transmission of the reference spectrum (Ref) grouped by wafer and testsite.**"
      ],
      "metadata": {
        "id": "W9g4ZlWfLCdY"
      },
      "id": "W9g4ZlWfLCdY"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# plz paste the path in the res pile\n",
        "file_path = './needed/analysis_result_ex.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "df.columns = [col.strip().replace(' ', '_').replace('.', '') for col in df.columns]\n",
        "\n",
        "grouped = df.groupby(['Wafer', 'TestSite'])\n",
        "\n",
        "fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for ax, ((wafer, testsite), group) in zip(axs[:-1], grouped):\n",
        "\n",
        "    data = group[['Row', 'Column', 'Max_transmission_of_Ref_spec_(dB)']].dropna()\n",
        "\n",
        "    x = data['Column']\n",
        "    y = data['Row']\n",
        "    z = data['Max_transmission_of_Ref_spec_(dB)']\n",
        "\n",
        "    xi = np.linspace(-5, 5, 100)\n",
        "    yi = np.linspace(-5, 5, 100)\n",
        "    zi = griddata((x, y), z, (xi[None, :], yi[:, None]), method='linear')\n",
        "\n",
        "\n",
        "    contour = ax.contourf(xi, yi, zi, cmap='viridis')\n",
        "    # cmap='viridis' or 'seismic' or 'plasma'\n",
        "\n",
        "    ax.scatter(x, y, color='black', marker='o', s=10, label='Original Data Points')\n",
        "    ax.set_title(f'Wafer: {wafer}, TestSite: {testsite}')\n",
        "    ax.set_xlabel('Column')\n",
        "    ax.set_ylabel('Row')\n",
        "\n",
        "    cbar = plt.colorbar(contour, ax=ax, orientation='vertical')\n",
        "    cbar.set_label('Max transmission of Ref. spec. (dB)')\n",
        "\n",
        "axs[-1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "LEHDFBZMcWpX",
        "outputId": "e1ae364e-02ca-4155-b0ec-9e4d6cd020fa"
      },
      "id": "LEHDFBZMcWpX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: './needed/analysis_result.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-95d9fef7516f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# plz paste the path in the res pile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./needed/analysis_result.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1497\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './needed/analysis_result.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is a heatmap of the maximum transmission of the reference spectrum (Ref) grouped by wafer, testsite, and date.**\n",
        "\n",
        "The last two graphs represent a single measurement session that was split due to passing dates during the measurement."
      ],
      "metadata": {
        "id": "p9P8SCsGLDFC"
      },
      "id": "p9P8SCsGLDFC"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "file_path = './needed/analysis_result_ex.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "\n",
        "df.columns = [col.strip().replace(' ', '_').replace('.', '') for col in df.columns]\n",
        "\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
        "\n",
        "\n",
        "grouped = df.groupby(['Wafer', 'TestSite', 'Date'])\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for ax, ((wafer, testsite, date), group) in zip(axs, grouped):\n",
        "\n",
        "    data = group[['Row', 'Column', 'Max_transmission_of_Ref_spec_(dB)']].dropna()\n",
        "\n",
        "\n",
        "    x = data['Column']\n",
        "    y = data['Row']\n",
        "    z = data['Max_transmission_of_Ref_spec_(dB)']\n",
        "\n",
        "    xi = np.linspace(-5, 5, 100)\n",
        "    yi = np.linspace(-5, 5, 100)\n",
        "    zi = griddata((x, y), z, (xi[None, :], yi[:, None]), method='linear')\n",
        "\n",
        "\n",
        "    contour = ax.contourf(xi, yi, zi, cmap='viridis')\n",
        "    # cmap='viridis' or 'seismic' or 'plasma'\n",
        "\n",
        "    ax.scatter(x, y, color='black', marker='o', s=10, label='Original Data')\n",
        "    ax.set_title(f'Wafer: {wafer}, TestSite: {testsite}, Date: {date}')\n",
        "    ax.set_xlabel('Column')\n",
        "    ax.set_ylabel('Row')\n",
        "\n",
        "\n",
        "    cbar = plt.colorbar(contour, ax=ax, orientation='vertical')\n",
        "    cbar.set_label('Max transmission of Ref. spec. (dB)')\n",
        "\n",
        "\n",
        "for ax in axs[len(grouped):]:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "As-KW0skezVx",
        "outputId": "0a7326b8-b310-4b68-b62b-5fcddfae5ee8"
      },
      "id": "As-KW0skezVx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: './needed/analysis_result.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9c39e648a314>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./needed/analysis_result.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1497\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './needed/analysis_result.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/Untitled Folder/analysis_result_ex.xlsx"
      ],
      "metadata": {
        "id": "EnvADSk1Rne0"
      },
      "id": "EnvADSk1Rne0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f1acb8cc-5e20-4d07-81f7-d68749e2f784"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}